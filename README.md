#hq-bot
A bot for the game HQ Trivia for CS 410 final project.

1) HQ Bot is a project that given an HQ Trivia question screen, can choose an answer in less than 20 seconds with greater accuracy than an average human. Users that would like to perform well at HQ Trivia (or see their friends win and feel left out) can use HQ Bot as a tool to becoming a more accurate HQ Trivia player with the aid of answer choices recommended by the system. For background, HQ Trivia is a game that occurs twice a day where contestants from all around the world tune into the same trivia game with the same set of 12 questions and same host. If a contestant gets all 12 questions correct, which have 4 options each, they will split a prize pool of thousands of dollars between the winners. This has been anywhere from a few cents to thousands of dollars over the past year, and the prize pool is continuing to grow with more sponsorships. Therein lies the motivation to create a system better than an average human being to increase a user’s chance of winning a seemingly ever-increasing pool of money.

2) There were a couple key libraries used to create the system, including Google Vision, Google Search, and OpenCV, and those details will be addressed in the following section. There were many things we learned along the way that constrained our system, and those will be discussed as well, which will explain our architecture. The high-level architecture is as follows when main.py is called: The system takes a picture which should include a clear image of the HQ Trivia question screen with no other text in the image. OpenCV is used on this image to identify all text and partition it into the question and option choices. With each question-choice pair, we make a Google query of “[question] AND [choice]” and retrieve the top 5 documents. We then take each word of the choice (except stop words from NLTK), and get a total probability of the query by multiplying all individual probabilities of words in choice. We found that cosine similarity was actually LESS accurate and we suspect that to be because our corpus of 5 documents was far too small for meaningful similarity functions. This fix isn’t trivial and we believe our implementation to be the best with the current resources because too many Google requests takes far longer than the allotted 10 seconds. With all the query-choice pairs, a probability is generated for each and winners are determined by those probabilities. Our system achieves around 67% accuracy and can go all the way to 90% accuracy in certain games (and as low as 55%). For future work, we would like to see the possibility of requesting more documents in parallel with a more powerful machine. This will likely give far better results because results are not constrained by top 5 documents.
3) For authentication of using Google’s library we have a file called secrets.py with our personal authentication. To run the program, one will have to create a Google Service account with access to Vision and Search and credits available to use. The secrets should have a GOOGLE_API_KEY and GOOGLE_CUSTOM_SEARCH_ID variable with correct values. The user must also download an authentication file in JSON with their Google Vision API account (and also must have available credits). This file should be placed in the main folder of this project. Then, the user must type export GOOGLE_APPLICATION_CREDENTIALS="/home/user/Downloads/service-account-file.json" into their command line with the value being replaced by complete path to the JSON credentials files. The core libraries used must be installed. All can be installed via Pip. These libraries are google-api-python-client, nltk, opencv-python and bs4. Then the user must run main.py, hold up the image to the screen, and the answers will be generated on command line. MAKE SURE THAT YOU COVER ALL OTHER TEXT BESIDES QUESTION AND ANSWER, AND TAKE A CLEAR PICTURE WHEN RUNNING!
4) Rohin and Nathan were both responsible for the same tasks and worked together for every aspect, but Rohin contributed mostly to the OpenCV implementations and he also created an initial version with cosine similarity that was ultimately not used because of suboptimal performance. Nathan contributed mostly to the current implementation.
